{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# quantum ml classification\n\ncomparing quantum vs classical approaches for binary classification. using qiskit for the quantum stuff.\n\nthree models:\n1. classical SVM (rbf kernel) - the baseline\n2. quantum kernel SVM - quantum feature map + regular svm\n3. VQC - variational quantum classifier, fully parameterized circuit\n\ntesting on make_moons and iris (2d). these are small datasets so we dont really expect quantum advantage, this is more of a proof of concept."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nsys.path.append('..')\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score\nfrom pathlib import Path\n\nfrom src.data_utils import load_moons_dataset, load_iris_2d\nfrom src.quantum_classifier import train_vqc, predict_grid\nfrom src.quantum_kernel import (\n    train_quantum_kernel_svm, evaluate_quantum_kernel_svm,\n    predict_grid_quantum_kernel\n)\nfrom src.classical_baseline import (\n    train_classical_svm, evaluate_classical_svm, predict_grid_classical\n)\n\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (10, 6)\n\nRESULTS_DIR = Path('../results')\nRESULTS_DIR.mkdir(exist_ok=True)\n\nprint('imports done')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. load the datasets\n\ntwo datasets, both 2d (= 2 qubits). features scaled to [0, pi] bc the quantum feature map uses them as rotation angles."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# load both datasets\nX_train_moons, X_test_moons, y_train_moons, y_test_moons = load_moons_dataset(n_samples=200)\nX_train_iris, X_test_iris, y_train_iris, y_test_iris = load_iris_2d()\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\naxes[0].scatter(X_train_moons[:, 0], X_train_moons[:, 1],\n                c=y_train_moons, cmap='coolwarm', alpha=0.7, edgecolors='k', s=50)\naxes[0].set_title('make_moons')\naxes[0].set_xlabel('feature 1')\naxes[0].set_ylabel('feature 2')\n\naxes[1].scatter(X_train_iris[:, 0], X_train_iris[:, 1],\n                c=y_train_iris, cmap='coolwarm', alpha=0.7, edgecolors='k', s=50)\naxes[1].set_title('iris (2d)')\naxes[1].set_xlabel('sepal length (scaled)')\naxes[1].set_ylabel('sepal width (scaled)')\n\nplt.tight_layout()\nplt.savefig(RESULTS_DIR / 'datasets.png', dpi=150)\nplt.show()\n\nprint(f\"moons: {len(X_train_moons)} train, {len(X_test_moons)} test\")\nprint(f\"iris:  {len(X_train_iris)} train, {len(X_test_iris)} test\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. look at the quantum circuits\n\nthe ZZFeatureMap encodes our 2d data into a 2-qubit state. the ZZ entangling gates create correlations between qubits based on products of input features which is where the nonlinearity comes from. kind of like a polynomial kernel but quantum."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from src.quantum_classifier import build_feature_map, build_ansatz\n\nfm = build_feature_map(n_qubits=2, reps=2)\nprint(\"=== ZZFeatureMap (2 qubits, 2 reps) ===\")\nprint(fm.decompose().draw(output='text'))\n\nprint(\"\\n=== RealAmplitudes ansatz (2 qubits, 3 reps) ===\")\nans = build_ansatz(n_qubits=2, reps=3)\nprint(ans.decompose().draw(output='text'))\nprint(f\"\\ntrainable params: {ans.num_parameters}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. classical SVM baseline\n\ntraining classical svms first. rbf kernel svm is a strong baseline for 2d classification, gonna be hard to beat."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# classical svm\nclassical_svm_moons = train_classical_svm(X_train_moons, y_train_moons, kernel='rbf')\nacc_classical_moons, preds_classical_moons = evaluate_classical_svm(\n    classical_svm_moons, X_test_moons, y_test_moons\n)\nprint(f\"classical SVM on make_moons: {acc_classical_moons:.4f}\")\n\nclassical_svm_iris = train_classical_svm(X_train_iris, y_train_iris, kernel='rbf')\nacc_classical_iris, preds_classical_iris = evaluate_classical_svm(\n    classical_svm_iris, X_test_iris, y_test_iris\n)\nprint(f\"classical SVM on iris:       {acc_classical_iris:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. quantum kernel SVM\n\nquantum kernel approach: compute kernel matrix using quantum circuit, then feed into regular sklearn svm. the kernel value between two points is the state overlap (fidelity) of their encoded quantum states.\n\nnote: computing the kernel matrix is slow bc it runs a circuit for every pair of points."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# quantum kernel svm on make_moons\nprint(\"training quantum kernel SVM on make_moons...\")\nqk_svm_moons, qk_kernel_moons, qk_fm_moons = train_quantum_kernel_svm(\n    X_train_moons, y_train_moons, n_qubits=2, reps=2\n)\nacc_qk_moons, preds_qk_moons = evaluate_quantum_kernel_svm(\n    qk_svm_moons, qk_kernel_moons, X_train_moons, X_test_moons, y_test_moons\n)\nprint(f\"quantum kernel SVM on make_moons: {acc_qk_moons:.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# quantum kernel svm on iris\nprint(\"training quantum kernel SVM on iris...\")\nqk_svm_iris, qk_kernel_iris, qk_fm_iris = train_quantum_kernel_svm(\n    X_train_iris, y_train_iris, n_qubits=2, reps=2\n)\nacc_qk_iris, preds_qk_iris = evaluate_quantum_kernel_svm(\n    qk_svm_iris, qk_kernel_iris, X_train_iris, X_test_iris, y_test_iris\n)\nprint(f\"quantum kernel SVM on iris: {acc_qk_iris:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. variational quantum classifier (VQC)\n\nthe VQC is the fully quantum approach - feature map encodes the data, ansatz is the trainable part, optimized with COBYLA. kinda like a neural net but quantum.\n\nthis is the slowest one to train."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# VQC on make_moons - takes a while\nprint(\"training VQC on make_moons...\")\nvqc_moons, obj_vals_moons = train_vqc(\n    X_train_moons, y_train_moons,\n    n_qubits=2, feature_reps=2, ansatz_reps=3, maxiter=100\n)\n\npreds_vqc_moons = vqc_moons.predict(X_test_moons)\nacc_vqc_moons = accuracy_score(y_test_moons, preds_vqc_moons)\nprint(f\"VQC on make_moons: {acc_vqc_moons:.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# VQC on iris\nprint(\"training VQC on iris...\")\nvqc_iris, obj_vals_iris = train_vqc(\n    X_train_iris, y_train_iris,\n    n_qubits=2, feature_reps=2, ansatz_reps=3, maxiter=100\n)\n\npreds_vqc_iris = vqc_iris.predict(X_test_iris)\nacc_vqc_iris = accuracy_score(y_test_iris, preds_vqc_iris)\nprint(f\"VQC on iris: {acc_vqc_iris:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. training curves\n\nhow the VQC objective changes during training. should go down if the optimizer is working."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\naxes[0].plot(obj_vals_moons, linewidth=1.5, color='#2196F3')\naxes[0].set_xlabel('iteration')\naxes[0].set_ylabel('objective')\naxes[0].set_title('VQC training - make_moons')\naxes[0].grid(True, alpha=0.3)\n\naxes[1].plot(obj_vals_iris, linewidth=1.5, color='#FF6B6B')\naxes[1].set_xlabel('iteration')\naxes[1].set_ylabel('objective')\naxes[1].set_title('VQC training - iris')\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig(RESULTS_DIR / 'training_curves.png', dpi=150)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. decision boundaries\n\nplotting all three classifiers side by side. quantum kernel uses a coarser grid (30x30) bc computing the kernel for every grid point is slow."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# decision boundaries - make_moons\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\nX_all_moons = np.vstack([X_train_moons, X_test_moons])\n\n# classical\nxx, yy, Z_classical = predict_grid_classical(classical_svm_moons, X_all_moons)\naxes[0].contourf(xx, yy, Z_classical, alpha=0.3, cmap='coolwarm')\naxes[0].scatter(X_test_moons[:, 0], X_test_moons[:, 1], c=y_test_moons,\n               cmap='coolwarm', edgecolors='k', s=50)\naxes[0].set_title(f'classical SVM (acc={acc_classical_moons:.2f})')\n\n# quantum kernel\nprint(\"computing quantum kernel decision boundary...\")\nxx_qk, yy_qk, Z_qk = predict_grid_quantum_kernel(\n    qk_svm_moons, qk_kernel_moons, X_train_moons, X_all_moons, resolution=30\n)\naxes[1].contourf(xx_qk, yy_qk, Z_qk, alpha=0.3, cmap='coolwarm')\naxes[1].scatter(X_test_moons[:, 0], X_test_moons[:, 1], c=y_test_moons,\n               cmap='coolwarm', edgecolors='k', s=50)\naxes[1].set_title(f'quantum kernel SVM (acc={acc_qk_moons:.2f})')\n\n# vqc\nprint(\"computing VQC decision boundary...\")\nxx_vqc, yy_vqc, Z_vqc = predict_grid(vqc_moons, X_all_moons)\naxes[2].contourf(xx_vqc, yy_vqc, Z_vqc, alpha=0.3, cmap='coolwarm')\naxes[2].scatter(X_test_moons[:, 0], X_test_moons[:, 1], c=y_test_moons,\n               cmap='coolwarm', edgecolors='k', s=50)\naxes[2].set_title(f'VQC (acc={acc_vqc_moons:.2f})')\n\nfor ax in axes:\n    ax.set_xlabel('feature 1')\n    ax.set_ylabel('feature 2')\n\nplt.suptitle('decision boundaries - make_moons', fontsize=14, y=1.02)\nplt.tight_layout()\nplt.savefig(RESULTS_DIR / 'decision_boundaries_moons.png', dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# decision boundaries - iris\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\nX_all_iris = np.vstack([X_train_iris, X_test_iris])\n\nxx, yy, Z = predict_grid_classical(classical_svm_iris, X_all_iris)\naxes[0].contourf(xx, yy, Z, alpha=0.3, cmap='coolwarm')\naxes[0].scatter(X_test_iris[:, 0], X_test_iris[:, 1], c=y_test_iris,\n               cmap='coolwarm', edgecolors='k', s=50)\naxes[0].set_title(f'classical SVM (acc={acc_classical_iris:.2f})')\n\nprint(\"computing quantum kernel decision boundary for iris...\")\nxx_qk, yy_qk, Z_qk = predict_grid_quantum_kernel(\n    qk_svm_iris, qk_kernel_iris, X_train_iris, X_all_iris, resolution=30\n)\naxes[1].contourf(xx_qk, yy_qk, Z_qk, alpha=0.3, cmap='coolwarm')\naxes[1].scatter(X_test_iris[:, 0], X_test_iris[:, 1], c=y_test_iris,\n               cmap='coolwarm', edgecolors='k', s=50)\naxes[1].set_title(f'quantum kernel SVM (acc={acc_qk_iris:.2f})')\n\nprint(\"computing VQC decision boundary for iris...\")\nxx_vqc, yy_vqc, Z_vqc = predict_grid(vqc_iris, X_all_iris)\naxes[2].contourf(xx_vqc, yy_vqc, Z_vqc, alpha=0.3, cmap='coolwarm')\naxes[2].scatter(X_test_iris[:, 0], X_test_iris[:, 1], c=y_test_iris,\n               cmap='coolwarm', edgecolors='k', s=50)\naxes[2].set_title(f'VQC (acc={acc_vqc_iris:.2f})')\n\nfor ax in axes:\n    ax.set_xlabel('feature 1')\n    ax.set_ylabel('feature 2')\n\nplt.suptitle('decision boundaries - iris', fontsize=14, y=1.02)\nplt.tight_layout()\nplt.savefig(RESULTS_DIR / 'decision_boundaries_iris.png', dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. results summary\n\nputting it all together"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# bar chart comparison\nfig, ax = plt.subplots(figsize=(10, 6))\n\nmethods = ['classical SVM\\n(rbf)', 'quantum kernel\\nSVM', 'VQC']\nmoons_accs = [acc_classical_moons, acc_qk_moons, acc_vqc_moons]\niris_accs = [acc_classical_iris, acc_qk_iris, acc_vqc_iris]\n\nx = np.arange(len(methods))\nwidth = 0.3\n\nbars1 = ax.bar(x - width/2, moons_accs, width, label='make_moons',\n               color='#FF6B6B', alpha=0.8, edgecolor='black', linewidth=0.5)\nbars2 = ax.bar(x + width/2, iris_accs, width, label='iris (2d)',\n               color='#4ECDC4', alpha=0.8, edgecolor='black', linewidth=0.5)\n\nfor bars in [bars1, bars2]:\n    for bar in bars:\n        h = bar.get_height()\n        ax.annotate(f'{h:.2f}', xy=(bar.get_x() + bar.get_width()/2, h),\n                   xytext=(0, 3), textcoords='offset points', ha='center', fontsize=11)\n\nax.set_ylabel('test accuracy')\nax.set_title('quantum vs classical accuracy')\nax.set_xticks(x)\nax.set_xticklabels(methods)\nax.legend()\nax.set_ylim(0.7, 1.05)\nax.grid(True, alpha=0.3, axis='y')\n\nplt.tight_layout()\nplt.savefig(RESULTS_DIR / 'accuracy_comparison.png', dpi=150)\nplt.show()\n\n# print results table\nprint(\"\\n\" + \"=\"*55)\nprint(f\"{'method':<25} {'make_moons':>12} {'iris (2d)':>12}\")\nprint(\"=\"*55)\nprint(f\"{'classical SVM (rbf)':<25} {acc_classical_moons:>12.4f} {acc_classical_iris:>12.4f}\")\nprint(f\"{'quantum kernel SVM':<25} {acc_qk_moons:>12.4f} {acc_qk_iris:>12.4f}\")\nprint(f\"{'VQC':<25} {acc_vqc_moons:>12.4f} {acc_vqc_iris:>12.4f}\")\nprint(\"=\"*55)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## conclusions\n\nso basically:\n- **classical SVM** wins on both datasets. not surprising, these are tiny 2d datasets\n- **quantum kernel SVM** is pretty close though. the quantum feature map does a decent job as a kernel\n- **VQC** is hardest to train. COBYLA gets stuck in local minima sometimes, maybe a different optimizer would help\n\nthe whole point of quantum ml isn't really about beating classical on toy data though. the idea (from havlicek et al) is that quantum kernels could have an advantage on high-dimensional data where classical kernels struggle. this is just the proof of concept for the pipeline.\n\nwould be cool to try this on a bigger dataset or with more qubits but the simulation gets really slow."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}